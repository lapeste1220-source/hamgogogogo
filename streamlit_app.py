# -*- coding: utf-8 -*-
import os
import re
import datetime
from pathlib import Path

import numpy as np
import pandas as pd
import requests
import streamlit as st
import plotly.express as px

# --------------------------------------------------
# ê¸°ë³¸ ì„¤ì •
# --------------------------------------------------
st.set_page_config(page_title="í•¨ì°½ê³  ìˆ˜ì‹œÂ·ì •ì‹œ ì§„í•™ ê²€ìƒ‰ê¸°", layout="wide")

st.title("í•¨ì°½ê³  ìˆ˜ì‹œÂ·ì •ì‹œ ì§„í•™ ê²€ìƒ‰ê¸°")
st.caption("í•¨ì°½ê³  í•™ìƒ ë§ì¶¤ ìˆ˜ì‹œÂ·ì •ì‹œ ì¶”ì²œ Â· ìš°ë¦¬ í•™êµ ì…ê²° ê¸°ë°˜ ì§„í•™ ë„ìš°ë¯¸")

TODAY = datetime.date.today().isoformat()

DATA_DIR = Path(".")

SUSI_HISTORY_FILE = DATA_DIR / "ìˆ˜ì‹œì§„í•™ê´€ë¦¬(2025ë…„2ì›”4ì¼).csv"
SUSI_META_FILE = DATA_DIR / "2025ìˆ˜ì‹œì…ê²°.csv"
JUNGSI_FILE = DATA_DIR / "2025ì •ì‹œì…ê²°.csv"
CHOEJEO_FILE = DATA_DIR / "2025ìµœì €ëª¨ìŒ.csv"


# --------------------------------------------------
# ê¸€ê¼´ ì„¤ì • (ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê±´ë„ˆëœ€)
# --------------------------------------------------
def setup_font():
    try:
        import matplotlib.pyplot as plt
        from matplotlib import font_manager, rcParams

        font_path = Path("fonts") / "Pretendard-Bold.ttf"
        if font_path.exists():
            font_manager.fontManager.addfont(str(font_path))
            font_name = font_manager.FontProperties(fname=str(font_path)).get_name()
            rcParams["font.family"] = font_name
        plt.rcParams["axes.unicode_minus"] = False
    except Exception:
        pass


setup_font()


# --------------------------------------------------
# ê³µí†µ ìœ í‹¸
# --------------------------------------------------
def read_csv_kr(path: Path) -> pd.DataFrame:
    if not path.exists():
        return pd.DataFrame()
    for enc in ("utf-8-sig", "cp949", "euc-kr"):
        try:
            df = pd.read_csv(path, encoding=enc)
            break
        except Exception:
            df = None
    if df is None:
        return pd.DataFrame()
    # ì»¬ëŸ¼ëª… ê³µí†µ ì •ë¦¬: ì¤„ë°”ê¿ˆ/ê³µë°± ì œê±°
    cols = []
    for c in df.columns:
        c2 = str(c).replace("\n", "").replace("\r", "")
        c2 = re.sub(r"\s+", "", c2)
        cols.append(c2)
    df.columns = cols
    return df


@st.cache_data
def load_worldbank_tertiary_enrollment():
    """ê³µê°œ ë°ì´í„°: í•œêµ­ ê³ ë“±êµìœ¡ ìˆœìˆ˜ë“±ë¡ë¥  (World Bank)"""
    url = (
        "http://api.worldbank.org/v2/country/KOR/indicator/SE.TER.ENRR"
        "?format=json&per_page=120"
    )
    try:
        r = requests.get(url, timeout=5)
        r.raise_for_status()
        data = r.json()[1]
        records = []
        for item in data:
            year = int(item["date"])
            if year > datetime.date.today().year:
                continue
            value = item["value"]
            if value is None:
                continue
            records.append({"year": year, "value": float(value)})
        df = pd.DataFrame(records).sort_values("year")
        return df, None
    except Exception as e:
        # ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°
        example = pd.DataFrame(
            {
                "year": list(range(2010, 2024)),
                "value": np.linspace(70, 95, 14),
            }
        )
        return example, str(e)


@st.cache_data
def load_susi_history():
    df = read_csv_kr(SUSI_HISTORY_FILE)
    if df.empty:
        return df
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê¸°
    needed = [
        "í•™ë…„",
        "ë°˜",
        "ë²ˆí˜¸",
        "ì´ë¦„",
        "ëª¨ì§‘ì‹œê¸°",
        "ëŒ€í•™ëª…",
        "ì „í˜•ìœ í˜•",
        "ì „í˜•ëª…(ëŒ€)",
        "ê³„ì—´",
        "ëª¨ì§‘ë‹¨ìœ„",
        "ë“±ë¡ì—¬ë¶€",
        "ë‚´ë“±ê¸‰(í™˜ì‚°)",
    ]
    keep = [c for c in needed if c in df.columns]
    df = df[keep].copy()
    df["ë‚´ë“±ê¸‰(í™˜ì‚°)"] = pd.to_numeric(df.get("ë‚´ë“±ê¸‰(í™˜ì‚°)"), errors="coerce")
    return df


@st.cache_data
def load_susi_meta():
    return read_csv_kr(SUSI_META_FILE)


@st.cache_data
def load_jungsi():
    return read_csv_kr(JUNGSI_FILE)


@st.cache_data
def load_choejeo():
    return read_csv_kr(CHOEJEO_FILE)


def make_susi_cut_table(history_df: pd.DataFrame) -> pd.DataFrame:
    """ìš°ë¦¬ í•™êµ ìˆ˜ì‹œ í•©ê²©ì ë‚´ì‹  ì»· ê³„ì‚°"""
    if history_df.empty:
        return pd.DataFrame()
    # ìˆ˜ì‹œ + ë“±ë¡ ê¸°ì¤€
    susi = history_df.copy()
    susi = susi[susi["ëª¨ì§‘ì‹œê¸°"] == "ìˆ˜ì‹œ"]
    if "ë“±ë¡ì—¬ë¶€" in susi.columns:
        susi = susi[susi["ë“±ë¡ì—¬ë¶€"].astype(str).str.contains("ë“±ë¡|Y|í•©ê²©", na=False)]
    susi = susi.dropna(subset=["ëŒ€í•™ëª…", "ë‚´ë“±ê¸‰(í™˜ì‚°)"])
    if susi.empty:
        return pd.DataFrame()
    grp = (
        susi.groupby(["ëŒ€í•™ëª…", "ì „í˜•ëª…(ëŒ€)", "ê³„ì—´"], dropna=False)["ë‚´ë“±ê¸‰(í™˜ì‚°)"]
        .agg(
            í•©ê²©ììˆ˜="count",
            ë‚´ì‹ ì¤‘ì•™ê°’="median",
            ë‚´ì‹ 70ë°±ë¶„ìœ„=lambda x: x.quantile(0.7),
            ìµœê³ ë“±ê¸‰="min",
            ìµœì €ë“±ê¸‰="max",
        )
        .reset_index()
    )
    return grp


def add_susi_meta(cuts: pd.DataFrame, meta: pd.DataFrame, choejeo: pd.DataFrame):
    if cuts.empty:
        return cuts
    df = cuts.copy()
    meta_df = meta.copy()
    cho_df = choejeo.copy()

    # ì „í˜•êµ¬ë¶„ ìƒì„± (êµê³¼/ì¢…í•©/ë…¼ìˆ /ì‹¤ê¸°)
    if "ì „í˜•ì„¸ë¶€ìœ í˜•" in meta_df.columns:
        def classify_type(x: str) -> str:
            if not isinstance(x, str):
                return "ê¸°íƒ€"
            if "êµê³¼" in x:
                return "êµê³¼"
            if "ì¢…í•©" in x:
                return "ì¢…í•©"
            if "ë…¼ìˆ " in x:
                return "ë…¼ìˆ "
            if "ì‹¤ê¸°" in x or "íŠ¹ê¸°" in x:
                return "ì‹¤ê¸°"
            return "ê¸°íƒ€"

        meta_df["ì „í˜•êµ¬ë¶„"] = meta_df["ì „í˜•ì„¸ë¶€ìœ í˜•"].apply(classify_type)
    else:
        meta_df["ì „í˜•êµ¬ë¶„"] = "ê¸°íƒ€"

    # ë©´ì ‘ìœ ë¬´, ë‹¨ê³„/ì¼ê´„
    if "ì „í˜•ë°©ë²•" not in meta_df.columns:
        meta_df["ì „í˜•ë°©ë²•"] = ""

    for col in ["ë©´ì ‘", "ë…¼ìˆ ", "ì‹¤ê¸°", "ì„œë¥˜"]:
        if col not in meta_df.columns:
            meta_df[col] = ""

    # ëŒ€í•™ ê¸°ì¤€ ë©”íƒ€ ì •ë³´ëŠ” ëŒ€í‘œ 1ê±´ë§Œ ì‚¬ìš©
    base_cols = [
        c
        for c in [
            "ëŒ€í•™ëª…",
            "ì§€ì—­êµ¬ë¶„",
            "ëŒ€í•™ì„¤ë¦½í˜•íƒœ",
            "ì „í˜•ì„¸ë¶€ìœ í˜•",
            "ì „í˜•êµ¬ë¶„",
            "ê³„ì—´",
            "ìƒì„¸ê³„ì—´",
            "ëª¨ì§‘ë‹¨ìœ„ëª…",
            "ì†Œì¬ì§€",
            "ì „í˜•ë°©ë²•",
            "ë©´ì ‘",
            "ë…¼ìˆ ",
            "ì‹¤ê¸°",
            "ì„œë¥˜",
        ]
        if c in meta_df.columns
    ]
    meta_base = meta_df[base_cols].drop_duplicates(subset=["ëŒ€í•™ëª…"])

    df = df.merge(meta_base, on="ëŒ€í•™ëª…", how="left")

    # ìµœì € ì •ë³´
    if not cho_df.empty:
        key_cols = [
            c
            for c in [
                "ëŒ€í•™ëª…",
                "ì „í˜•ì„¸ë¶€ìœ í˜•",
                "ìµœì €í•™ë ¥ê¸°ì¤€ë‚´ìš©",
            ]
            if c in cho_df.columns
        ]
        if key_cols:
            cho_base = cho_df[key_cols].drop_duplicates(subset=["ëŒ€í•™ëª…"])
            df = df.merge(cho_base, on="ëŒ€í•™ëª…", how="left")

    return df


def categorize_by_grade(df: pd.DataFrame, my_grade: float) -> pd.DataFrame:
    """ë‚´ì‹  ê¸°ì¤€ ì•ˆì „/ì ì •/ë„ì „ ë¶„ë¥˜"""
    d = df.copy()
    d = d.dropna(subset=["ë‚´ì‹ ì¤‘ì•™ê°’"])
    if d.empty:
        return d
    d["ì—¬ìœ ë„(ì¤‘ì•™ê°’-ë‚´ì‹ )"] = d["ë‚´ì‹ ì¤‘ì•™ê°’"] - my_grade
    # ì—¬ìœ ë„ê°€ í´ìˆ˜ë¡ ì•ˆì „
    conditions = [
        d["ì—¬ìœ ë„(ì¤‘ì•™ê°’-ë‚´ì‹ )"] >= 0.7,
        (d["ì—¬ìœ ë„(ì¤‘ì•™ê°’-ë‚´ì‹ )"] >= 0.3) & (d["ì—¬ìœ ë„(ì¤‘ì•™ê°’-ë‚´ì‹ )"] < 0.7),
        (d["ì—¬ìœ ë„(ì¤‘ì•™ê°’-ë‚´ì‹ )"] > -0.5) & (d["ì—¬ìœ ë„(ì¤‘ì•™ê°’-ë‚´ì‹ )"] < 0.3),
    ]
    choices = ["ì•ˆì „", "ì ì •", "ë„ì „"]
    d["ì¶”ì²œêµ¬ë¶„"] = np.select(conditions, choices, default="ìœ„í—˜")
    return d


def filter_susi_reco(
    df: pd.DataFrame,
    region: str,
    univ_type: str,
    jeonhyeong: list,
    need_choejeo: str,
    need_interview: str,
    step_type: str,
):
    if df.empty:
        return df
    res = df.copy()

    if region != "ì „ì²´" and "ì§€ì—­êµ¬ë¶„" in res.columns:
        res = res[res["ì§€ì—­êµ¬ë¶„"] == region]

    if univ_type != "ì „ì²´" and "ëŒ€í•™ì„¤ë¦½í˜•íƒœ" in res.columns:
        res = res[res["ëŒ€í•™ì„¤ë¦½í˜•íƒœ"] == univ_type]

    if jeonhyeong and "ì „í˜•êµ¬ë¶„" in res.columns:
        res = res[res["ì „í˜•êµ¬ë¶„"].isin(jeonhyeong)]

    # ìµœì € ìœ ë¬´
    if need_choejeo != "ìƒê´€ì—†ìŒ" and "ìµœì €í•™ë ¥ê¸°ì¤€ë‚´ìš©" in res.columns:
        has_cho = res["ìµœì €í•™ë ¥ê¸°ì¤€ë‚´ìš©"].notna() & res["ìµœì €í•™ë ¥ê¸°ì¤€ë‚´ìš©"].astype(str).str.strip().ne(
            ""
        )
        if need_choejeo == "ìµœì €ìˆìŒ":
            res = res[has_cho]
        elif need_choejeo == "ìµœì €ì—†ìŒ":
            res = res[~has_cho]

    # ë©´ì ‘ ìœ ë¬´
    if need_interview != "ìƒê´€ì—†ìŒ" and "ë©´ì ‘" in res.columns:
        has_intv = res["ë©´ì ‘"].astype(str).str.contains(r"\d|ì |ë°˜ì˜|ì‹¤ì‹œ", na=False)
        if need_interview == "ë©´ì ‘ìˆìŒ":
            res = res[has_intv]
        elif need_interview == "ë©´ì ‘ì—†ìŒ":
            res = res[~has_intv]

    # ë‹¨ê³„/ì¼ê´„
    if step_type != "ìƒê´€ì—†ìŒ" and "ì „í˜•ë°©ë²•" in res.columns:
        col = res["ì „í˜•ë°©ë²•"].astype(str)
        if step_type == "ë‹¤ë‹¨ê³„ì „í˜•":
            res = res[col.str.contains("ë‹¨ê³„", na=False)]
        elif step_type == "ì¼ê´„ì„ ë°œ":
            res = res[~col.str.contains("ë‹¨ê³„", na=False)]

    return res


def get_jungsi_reco(df: pd.DataFrame, my_percent: float, top_n=5):
    if df.empty:
        return pd.DataFrame()
    d = df.copy()
    if "ë°˜ì˜ì˜ì—­í‰ê· ë°±ë¶„ìœ„" not in d.columns:
        return pd.DataFrame()
    d["cut"] = pd.to_numeric(d["ë°˜ì˜ì˜ì—­í‰ê· ë°±ë¶„ìœ„"], errors="coerce")
    d = d.dropna(subset=["cut"])
    d["ì—¬ìœ ë„(ë°±ë¶„ìœ„-ì»·)"] = my_percent - d["cut"]
    d["ì í•©ë„"] = -np.abs(d["ì—¬ìœ ë„(ë°±ë¶„ìœ„-ì»·)"])
    d = d.sort_values("ì í•©ë„", ascending=True).copy()
    return d.head(top_n)


# --------------------------------------------------
# UI: íƒ­ êµ¬ì„±
# --------------------------------------------------
tab_public, tab_local = st.tabs(["ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ", "í•¨ì°½ê³  ìˆ˜ì‹œÂ·ì •ì‹œ ê²€ìƒ‰ê¸°"])

# --------------------------------------------------
# 1. ê³µê°œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ
# --------------------------------------------------
with tab_public:
    st.subheader("ê³µê°œ ë°ì´í„°: í•œêµ­ ê³ ë“±êµìœ¡ ìˆœìˆ˜ ì¬í•™ë¥  ì¶”ì´ (World Bank)")

    wb_df, wb_err = load_worldbank_tertiary_enrollment()
    if wb_err:
        st.info("ì‹¤ì‹œê°„ World Bank API í˜¸ì¶œì— ì‹¤íŒ¨í•˜ì—¬ ì˜ˆì‹œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    st.write("ë‹¨ìœ„: ìˆœìˆ˜ ì¬í•™ë¥ (%)")
    fig = px.line(
        wb_df,
        x="year",
        y="value",
        markers=True,
        labels={"year": "ì—°ë„", "value": "ìˆœìˆ˜ ì¬í•™ë¥ (%)"},
        title="í•œêµ­ ê³ ë“±êµìœ¡ ìˆœìˆ˜ ì¬í•™ë¥  ì¶”ì´",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.dataframe(wb_df, use_container_width=True)

    csv_bytes = wb_df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "ê³µê°œ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
        data=csv_bytes,
        file_name=f"worldbank_tertiary_enrollment_KOR_{TODAY}.csv",
        mime="text/csv",
    )

# --------------------------------------------------
# 2. í•¨ì°½ê³  ìˆ˜ì‹œÂ·ì •ì‹œ ê²€ìƒ‰ê¸°
# --------------------------------------------------
with tab_local:
    st.subheader("í•¨ì°½ê³  ìˆ˜ì‹œÂ·ì •ì‹œ ì§„í•™ ê²€ìƒ‰ê¸° (ë‚´ì‹ Â·ëª¨ì˜ê³ ì‚¬Â·ìš°ë¦¬ í•™êµ ì…ê²° ê¸°ë°˜)")

    # ë°ì´í„° ë¡œë“œ
    susi_history = load_susi_history()
    susi_meta = load_susi_meta()
    jungsi_df = load_jungsi()
    choejeo_df = load_choejeo()

    if susi_history.empty:
        st.warning("ìˆ˜ì‹œì§„í•™ê´€ë¦¬ CSVë¥¼ ì½ì–´ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œì™€ ì¸ì½”ë”©ì„ í™•ì¸í•˜ì„¸ìš”.")

    cuts = make_susi_cut_table(susi_history)
    cuts_meta = add_susi_meta(cuts, susi_meta, choejeo_df)

    st.markdown("### 1. ìˆ˜ì‹œ ì¶”ì²œ ëŒ€í•™ (ìš°ë¦¬ í•™êµ ì…ê²° + ë‚´ì‹  ê¸°ì¤€)")

    col_left, col_right = st.columns([1, 2])

    with col_left:
        my_grade = st.number_input(
            "ë‚˜ì˜ ë‚´ì‹  í‰ê· ë“±ê¸‰ (ì „êµê³¼ ë˜ëŠ” ì£¼ìš” ë°˜ì˜ ë‚´ì‹ )",
            min_value=1.0,
            max_value=9.0,
            step=0.1,
            value=3.0,
        )

        region_options = ["ì „ì²´"]
        if "ì§€ì—­êµ¬ë¶„" in cuts_meta.columns:
            region_options += sorted(cuts_meta["ì§€ì—­êµ¬ë¶„"].dropna().unique().tolist())
        region = st.selectbox("ì§€ì—­ ì„ íƒ", region_options)

        univ_type_options = ["ì „ì²´"]
        if "ëŒ€í•™ì„¤ë¦½í˜•íƒœ" in cuts_meta.columns:
            univ_type_options += sorted(cuts_meta["ëŒ€í•™ì„¤ë¦½í˜•íƒœ"].dropna().unique().tolist())
        univ_type = st.selectbox("ëŒ€í•™ ì„¤ë¦½ ìœ í˜•", univ_type_options)

        jg_options = ["êµê³¼", "ì¢…í•©", "ë…¼ìˆ ", "ì‹¤ê¸°"]
        jeonhyeong_sel = st.multiselect("ì „í˜• êµ¬ë¶„ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)", jg_options, default=jg_options[:2])

        choejeo_sel = st.radio(
            "ìˆ˜ëŠ¥ ìµœì €í•™ë ¥ê¸°ì¤€",
            ["ìƒê´€ì—†ìŒ", "ìµœì €ìˆìŒ", "ìµœì €ì—†ìŒ"],
            horizontal=True,
        )

        interview_sel = st.radio(
            "ë©´ì ‘ ì „í˜• ì—¬ë¶€",
            ["ìƒê´€ì—†ìŒ", "ë©´ì ‘ìˆìŒ", "ë©´ì ‘ì—†ìŒ"],
            horizontal=True,
        )

        step_sel = st.radio(
            "ë‹¨ê³„/ì¼ê´„ ì„ ë°œ",
            ["ìƒê´€ì—†ìŒ", "ë‹¤ë‹¨ê³„ì „í˜•", "ì¼ê´„ì„ ë°œ"],
            horizontal=True,
        )

        susi_button = st.button("âœ… ìˆ˜ì‹œ ì¶”ì²œ ëŒ€í•™ ê²€ìƒ‰")

    with col_right:
        if cuts_meta.empty:
            st.info("ì•„ì§ ìš°ë¦¬ í•™êµ ìˆ˜ì‹œ í•©ê²© ë‚´ì—­ì´ ë¶€ì¡±í•˜ì—¬ ì¶”ì²œ ê³„ì‚°ì´ ì–´ë µìŠµë‹ˆë‹¤.")
        elif susi_button:
            base = categorize_by_grade(cuts_meta, my_grade)
            base = filter_susi_reco(
                base,
                region=region,
                univ_type=univ_type,
                jeonhyeong=jeonhyeong_sel,
                need_choejeo=choejeo_sel,
                need_interview=interview_sel,
                step_type=step_sel,
            )

            if base.empty:
                st.warning("ì¡°ê±´ì— ë§ëŠ” ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ ë³´ì„¸ìš”.")
            else:
                safe = base[base["ì¶”ì²œêµ¬ë¶„"] == "ì•ˆì „"].sort_values(
                    "ì—¬ìœ ë„(ì¤‘ì•™ê°’-ë‚´ì‹ )", ascending=False
                ).head(2)
                fit = base[base["ì¶”ì²œêµ¬ë¶„"] == "ì ì •"].sort_values(
                    "ì—¬ìœ ë„(ì¤‘ì•™ê°’-ë‚´ì‹ )", ascending=False
                ).head(2)
                risk = base[base["ì¶”ì²œêµ¬ë¶„"] == "ë„ì „"].sort_values(
                    "ì—¬ìœ ë„(ì¤‘ì•™ê°’-ë‚´ì‹ )", ascending=False
                ).head(2)

                st.markdown("#### ğŸ”µ ì•ˆì „ ì§€ì›ê¶Œ (2ê°œ ë‚´ì™¸)")
                st.dataframe(safe, use_container_width=True)

                st.markdown("#### ğŸŸ¢ ì ì • ì§€ì›ê¶Œ (2ê°œ ë‚´ì™¸)")
                st.dataframe(fit, use_container_width=True)

                st.markdown("#### ğŸŸ  ë„ì „ ì§€ì›ê¶Œ (2ê°œ ë‚´ì™¸)")
                st.dataframe(risk, use_container_width=True)

                all_reco = pd.concat([safe, fit, risk], ignore_index=True)
                csv_bytes = all_reco.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ìˆ˜ì‹œ ì¶”ì²œ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv_bytes,
                    file_name=f"hamchang_susi_recommend_{TODAY}.csv",
                    mime="text/csv",
                )
        else:
            st.info("ì™¼ìª½ì—ì„œ ë‚´ì‹ ê³¼ í•„í„°ë¥¼ ì…ë ¥í•œ ë’¤ â€˜ìˆ˜ì‹œ ì¶”ì²œ ëŒ€í•™ ê²€ìƒ‰â€™ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")

    st.markdown("---")
    st.markdown("### 2. ì •ì‹œ ì¶”ì²œ ëŒ€í•™ (ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ ê¸°ì¤€)")

    col_j1, col_j2 = st.columns([1, 2])

    with col_j1:
        my_percent = st.number_input(
            "ë‚˜ì˜ ë°˜ì˜ì˜ì—­ í‰ê·  ë°±ë¶„ìœ„ (ìµœê·¼ ëª¨ì˜ê³ ì‚¬ ê¸°ì¤€)",
            min_value=0.0,
            max_value=100.0,
            step=0.5,
            value=85.0,
        )
        jung_button = st.button("âœ… ì •ì‹œ ì¶”ì²œ ëŒ€í•™ ê²€ìƒ‰")

    with col_j2:
        if jungsi_df.empty:
            st.warning("ì •ì‹œ ì…ê²° CSVë¥¼ ì½ì–´ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        elif jung_button:
            reco_j = get_jungsi_reco(jungsi_df, my_percent, top_n=5)
            if reco_j.empty:
                st.warning("ì •ì‹œ ì¶”ì²œ ê²°ê³¼ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSVì˜ 'ë°˜ì˜ì˜ì—­ í‰ê· ë°±ë¶„ìœ„' ì»¬ëŸ¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            else:
                st.dataframe(reco_j, use_container_width=True)
                csv_bytes = reco_j.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ì •ì‹œ ì¶”ì²œ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv_bytes,
                    file_name=f"hamchang_jungsi_recommend_{TODAY}.csv",
                    mime="text/csv",
                )
        else:
            st.info("ì™¼ìª½ì—ì„œ í‰ê·  ë°±ë¶„ìœ„ë¥¼ ì…ë ¥í•œ ë’¤ â€˜ì •ì‹œ ì¶”ì²œ ëŒ€í•™ ê²€ìƒ‰â€™ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")

    st.markdown("---")
    st.markdown("### 3. í•™ìƒë¶€ì¢…í•© ì „í˜• ì í•©ë„ ìê°€ ì§„ë‹¨")

    st.caption("ê° ë¬¸í•­ì— ëŒ€í•´ 1ì (ì „í˜€ ì•„ë‹ˆë‹¤) ~ 5ì (ë§¤ìš° ê·¸ë ‡ë‹¤)ë¡œ ì†”ì§í•˜ê²Œ ì²´í¬í•´ ë³´ì„¸ìš”.")

    q_labels = [
        "ì´ìˆ˜ ê³¼ëª©(ì„ íƒê³¼ëª© í¬í•¨)ì´ ë‹¤ì–‘í•œ í¸ì´ë‹¤.",
        "ì£¼ìš” êµê³¼ ì„±ì·¨ë„ê°€ ìš°ìˆ˜í•œ í¸ì´ë‹¤.",
        "ììœ¨Â·ì§„ë¡œÂ·ë™ì•„ë¦¬ í™œë™ì´ ê¾¸ì¤€í•˜ê³  ë‚´ìš©ì´ ìˆë‹¤.",
        "ë¦¬ë”ì‹­Â·ë°°ë ¤Â·ë´‰ì‚¬Â·ì˜ì‚¬ì†Œí†µÂ·ê³µë™ì²´ ì—­ëŸ‰ì„ ë³´ì—¬ì£¼ëŠ” ì‚¬ë¡€ê°€ ìˆë‹¤.",
        "í”„ë¡œì íŠ¸Â·ìº í˜ì¸Â·ë³´ê³ ì„œ í™œë™ ê²½í—˜ì´ ìˆë‹¤.",
        "ë…ì„œ í™œë™ì´ í’ë¶€í•˜ê³  í™œë™ê³¼ ì˜ ì—°ê²°ë˜ì–´ ìˆë‹¤.",
        "ì‹¤íŒ¨ ê²½í—˜ê³¼ ê·¹ë³µ ê²½í—˜ì„ ìŠ¤ìŠ¤ë¡œ ì„±ì°°í•´ ë³¸ ì ì´ ìˆë‹¤.",
        "í•™êµ í™œë™ ì „ë°˜ì„ ê´€í†µí•˜ëŠ” ë‚˜ë§Œì˜ í‚¤ì›Œë“œ/ì£¼ì œê°€ ìˆë‹¤.",
        "ìƒí™œê¸°ë¡ë¶€ì— ê¸°ë¡ëœ í™œë™ì— ëŒ€í•´ ìì‹  ìˆê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.",
        "ë©´ì ‘ì—ì„œ ìì‹ ì˜ ìƒê°ì„ ì¡°ë¦¬ ìˆê²Œ ë§í•  ìˆ˜ ìˆë‹¤.",
    ]

    scores = []
    for i, q in enumerate(q_labels, start=1):
        val = st.slider(f"{i}) {q}", min_value=1, max_value=5, value=3)
        scores.append(val)

    total = sum(scores)
    st.write(f"**ì´ì : {total}ì  (ìµœëŒ€ 50ì )**")

    if total >= 40:
        level = "ë§¤ìš° ì ì •"
        desc = "í•™ìƒë¶€ì¢…í•© ì „í˜•ì— ë§¤ìš° ì˜ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    elif total >= 30:
        level = "ì ì •"
        desc = "í•™ìƒë¶€ì¢…í•© ì „í˜• ì§€ì›ì— ë¹„êµì  ì í•©í•œ ìƒíƒœì…ë‹ˆë‹¤."
    elif total >= 25:
        level = "ë³´í†µ"
        desc = "ê¸°ë³¸ ì¤€ë¹„ëŠ” ë˜ì–´ ìˆìœ¼ë‚˜, ëª‡ ê°€ì§€ ì˜ì—­ì—ì„œ ë³´ì™„ì´ í•„ìš”í•©ë‹ˆë‹¤."
    elif total >= 20:
        level = "ë³´ì™„ í•„ìš”"
        desc = "ì¤‘ìš” ìš”ì†Œë“¤ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‚¨ì€ ê¸°ê°„ ë™ì•ˆ ê³„íšì ì¸ ë³´ì™„ì´ í•„ìš”í•©ë‹ˆë‹¤."
    else:
        level = "ë¯¸í¡"
        desc = "í•™ìƒë¶€ì¢…í•© ì „í˜•ë³´ë‹¤ëŠ” ë‹¤ë¥¸ ì „í˜•(êµê³¼Â·ì •ì‹œ ë“±)ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì „ëµì„ ì„¸ìš°ëŠ” ê²ƒì´ ì¢‹ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

    st.success(f"ì¢…í•© ì§„ë‹¨ ê²°ê³¼: **{level}**")
    st.write(desc)

    st.markdown("---")
    st.markdown("### 4. ìµœì € ê¸°ì¤€ & ìš°ë¦¬ í•™êµ í•©ê²© ë‚´ì‹  ë¹„êµ")

    cho_cols_ok = (
        ("ëŒ€í•™ëª…" in choejeo_df.columns) and ("ìµœì €í•™ë ¥ê¸°ì¤€ë‚´ìš©" in choejeo_df.columns)
    )
    if not cho_cols_ok:
        st.info("ìµœì €í•™ë ¥ ê¸°ì¤€ CSVì—ì„œ ëŒ€í•™ëª…/ìµœì €í•™ë ¥ê¸°ì¤€ ë‚´ìš© ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        uni_list = sorted(choejeo_df["ëŒ€í•™ëª…"].dropna().unique().tolist())
        sel_uni = st.selectbox("ëŒ€í•™ ì„ íƒ", ["ì„ íƒ ì•ˆ í•¨"] + uni_list)

        if sel_uni != "ì„ íƒ ì•ˆ í•¨":
            sub = choejeo_df[choejeo_df["ëŒ€í•™ëª…"] == sel_uni]
            st.markdown("#### ì„ íƒ ëŒ€í•™ì˜ ëŒ€í‘œ ìµœì € ê¸°ì¤€ ì˜ˆì‹œ")
            st.dataframe(
                sub[["ëŒ€í•™ëª…", "ì „í˜•ì„¸ë¶€ìœ í˜•", "ê³„ì—´", "ëª¨ì§‘ë‹¨ìœ„ëª…", "ìµœì €í•™ë ¥ê¸°ì¤€ë‚´ìš©"]],
                use_container_width=True,
            )

            my_grade_for_uni = st.number_input(
                "í•´ë‹¹ ëŒ€í•™ ì§€ì› ê°€ì • ì‹œ ë‚˜ì˜ ë‚´ì‹  ë“±ê¸‰ (ë°˜ì˜ ê¸°ì¤€)",
                min_value=1.0,
                max_value=9.0,
                step=0.1,
                value=my_grade,
            )

            # ìš°ë¦¬ í•™êµ í•©ê²©ì í†µê³„
            if not cuts.empty:
                hist_uni = cuts[cuts["ëŒ€í•™ëª…"] == sel_uni]
            else:
                hist_uni = pd.DataFrame()

            if hist_uni.empty:
                st.info("í•´ë‹¹ ëŒ€í•™ì˜ ìš°ë¦¬ í•™êµ í•©ê²© ë°ì´í„°ê°€ ì•„ì§ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            else:
                st.markdown("#### ìš°ë¦¬ í•™êµ í•©ê²©ì ë‚´ì‹  í†µê³„")
                st.dataframe(hist_uni, use_container_width=True)

                avg_cut = hist_uni["ë‚´ì‹ ì¤‘ì•™ê°’"].mean()
                diff = avg_cut - my_grade_for_uni
                if diff >= 0.7:
                    msg = "ìš°ë¦¬ í•™êµ í‰ê·  í•©ê²©ìë³´ë‹¤ **ìƒëŒ€ì ìœ¼ë¡œ ì—¬ìœ  ìˆëŠ” ë‚´ì‹ **ì…ë‹ˆë‹¤."
                elif diff >= 0.3:
                    msg = "ìš°ë¦¬ í•™êµ í‰ê·  í•©ê²©ì ìˆ˜ì¤€ì— **ê·¼ì ‘í•œ ë‚´ì‹ **ì…ë‹ˆë‹¤."
                elif diff > -0.5:
                    msg = "ìš°ë¦¬ í•™êµ í•©ê²©ì í‰ê· ë³´ë‹¤ **ë‹¤ì†Œ ë¶ˆë¦¬í•œ ë‚´ì‹ **ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ê°•ì ì„ í•¨ê»˜ ë³´ì—¬ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤."
                else:
                    msg = "ìš°ë¦¬ í•™êµ ê¸°ì¤€ìœ¼ë¡œ ë³¼ ë•Œ **ìƒë‹¹íˆ ë„ì „ì ì¸ ë‚´ì‹ **ì…ë‹ˆë‹¤."

                st.success(
                    f"ë‚´ì‹  ë¹„êµ ê²°ê³¼: ë‹¹ì‹ ì˜ ë‚´ì‹ ({my_grade_for_uni:.1f}) vs ìš°ë¦¬ í•™êµ í‰ê·  í•©ê²© ë‚´ì‹ ({avg_cut:.2f}) â†’ {msg}"
                )

    # --------------------------------------------------
    # ì •ë¦¬ëœ ë°ì´í„° ì¼ê´„ ë‹¤ìš´ë¡œë“œ (ì„ íƒ)
    # --------------------------------------------------
    st.markdown("---")
    st.markdown("### 5. ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

    col_d1, col_d2, col_d3, col_d4 = st.columns(4)

    with col_d1:
        if not susi_history.empty:
            st.download_button(
                "ìš°ë¦¬ í•™êµ ìˆ˜ì‹œ ì§„í•™ ê´€ë¦¬ ì›ë³¸ CSV",
                data=susi_history.to_csv(index=False).encode("utf-8-sig"),
                file_name="hamchang_susi_history_raw.csv",
                mime="text/csv",
            )

    with col_d2:
        if not cuts_meta.empty:
            st.download_button(
                "ìˆ˜ì‹œ í•©ê²© ë‚´ì‹  ì»· í…Œì´ë¸” CSV",
                data=cuts_meta.to_csv(index=False).encode("utf-8-sig"),
                file_name="hamchang_susi_cut_with_meta.csv",
                mime="text/csv",
            )

    with col_d3:
        if not jungsi_df.empty:
            st.download_button(
                "ì •ì‹œ ì…ê²° ì›ë³¸ CSV",
                data=jungsi_df.to_csv(index=False).encode("utf-8-sig"),
                file_name="hamchang_jungsi_raw.csv",
                mime="text/csv",
            )

    with col_d4:
        if not choejeo_df.empty:
            st.download_button(
                "ìˆ˜ëŠ¥ ìµœì € ê¸°ì¤€ ì›ë³¸ CSV",
                data=choejeo_df.to_csv(index=False).encode("utf-8-sig"),
                file_name="hamchang_choejeo_raw.csv",
                mime="text/csv",
            )

# ---------------- í™”ë©´ ì¢Œì¸¡ í•˜ë‹¨ 'ì œì‘ì' í‘œì‹œ ----------------
st.markdown(
    """
    <div style="position: fixed; bottom: 10px; left: 10px; 
                font-size: 0.9rem; color: gray; background-color: rgba(255,255,255,0.7);
                padding: 4px 8px; border-radius: 4px;">
        ì œì‘ì í•¨ì°½ê³  êµ­ì–´êµì‚¬ ë°•í˜¸ì¢…
    </div>
    """,
    unsafe_allow_html=True,
)
