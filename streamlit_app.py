# ---- ë³´ì•ˆ: ë¹„ë°€ë²ˆí˜¸ í™•ì¸ ----
import streamlit as st

PASSWORD = "hamchang123"   # ì›í•˜ëŠ” ë¹„ë°€ë²ˆí˜¸ë¡œ ë³€ê²½

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.title("ğŸ”’ í•¨ì°½ê³  ìˆ˜ì‹œÂ·ì •ì‹œ ê²€ìƒ‰ê¸° ë³´ì•ˆ ì ‘ì†")
    pwd = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")

    if st.button("ì ‘ì†"):
        if pwd == PASSWORD:
            st.session_state.authenticated = True
            st.rerun()
        else:
            st.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
    st.stop()

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import re
import altair as alt

# ---------------- ê¸°ë³¸ ì„¤ì • ----------------
st.set_page_config(
    page_title="í•¨ì°½ê³  ìˆ˜ì‹œÂ·ì •ì‹œ ê²€ìƒ‰ê¸°",
    layout="wide",
)

st.title("í•¨ì°½ê³  ìˆ˜ì‹œÂ·ì •ì‹œ ê²€ìƒ‰ê¸°")
st.caption("í•¨ì°½ê³  ì…ê²° + 2025 ì–´ë””ê°€ ìˆ˜ì‹œÂ·ì •ì‹œÂ·ìµœì € ë°ì´í„°ë¥¼ í•¨ê»˜ ë³´ëŠ” ì „ìš© ë„êµ¬ (ë² íƒ€)")

DATA_DIR = Path(".")

# í•¨ì°½ê³  ìˆ˜ì‹œì§„í•™ê´€ë¦¬: 2025 + 2024 íŒŒì¼ì„ í•©ì³ ì‚¬ìš©
SUJI_2025_FILE = DATA_DIR / "ìˆ˜ì‹œì§„í•™ê´€ë¦¬(2025ë…„2ì›”4ì¼).csv"
SUJI_2024_FILE = DATA_DIR / "ìˆ˜ì‹œì§„í•™ê´€ë¦¬(2024ë…„2ì›”20ì¼).csv"

# ì–´ë””ê°€ ìˆ˜ì‹œ/ì •ì‹œ/ìµœì €
SUSI_FILE = DATA_DIR / "2025ìˆ˜ì‹œì…ê²°.csv"
JEONG_FILE = DATA_DIR / "2025ì •ì‹œì…ê²°.csv"
CHOEJEO_FILE = DATA_DIR / "2025ìµœì €ëª¨ìŒ.csv"

# ì „ì—­ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜
SUSI_GRADE_COL = None
SU_DEPT_AVG = None
JEONG_SCORE_COL = None

# ---------------- ê³µí†µ ìœ í‹¸ ----------------
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.replace("\n", "").replace(" ", "") for c in df.columns]
    return df

@st.cache_data
def load_data():
    # 1) í•¨ì°½ê³  ìˆ˜ì‹œì§„í•™ê´€ë¦¬ (ì—°ë„ë³„ ë³‘í•©)
    suji_list = []

    if SUJI_2025_FILE.exists():
        df25 = pd.read_csv(SUJI_2025_FILE, encoding="utf-8")
        df25 = normalize_columns(df25)
        df25["ì…ì‹œì—°ë„"] = 2025
        suji_list.append(df25)

    if SUJI_2024_FILE.exists():
        df24 = pd.read_csv(SUJI_2024_FILE, encoding="utf-8")
        df24 = normalize_columns(df24)
        df24["ì…ì‹œì—°ë„"] = 2024
        suji_list.append(df24)

    suji = pd.concat(suji_list, ignore_index=True) if suji_list else None

    # 2) ì–´ë””ê°€ ìˆ˜ì‹œ/ì •ì‹œ/ìµœì €
    susi = jeong = choe = None
    if SUSI_FILE.exists():
        susi = pd.read_csv(SUSI_FILE, encoding="utf-8")
        susi = normalize_columns(susi)
    if JEONG_FILE.exists():
        jeong = pd.read_csv(JEONG_FILE, encoding="utf-8")
        jeong = normalize_columns(jeong)
    if CHOEJEO_FILE.exists():
        choe = pd.read_csv(CHOEJEO_FILE, encoding="utf-8")
        choe = normalize_columns(choe)

    return suji, susi, jeong, choe

suji_df, susi_df, jeong_df, choe_df = load_data()
# ---------------- ì–´ë””ê°€ ìˆ˜ì‹œ/ì •ì‹œ ë³´ì¡° í…Œì´ë¸” ----------------
if susi_df is not None:
    # ìˆ˜ì‹œ í‰ê·  ë‚´ì‹  ì»¬ëŸ¼ ì¶”ë¡ 
    grade_candidates = [
        c for c in susi_df.columns
        if any(k in c for k in ["í‰ê· ", "í‰ê· ë“±ê¸‰", "ë‚´ì‹ ", "ë“±ê¸‰"])
    ]
    SUSI_GRADE_COL = grade_candidates[0] if grade_candidates else None

    if SUSI_GRADE_COL is not None and SUSI_GRADE_COL in susi_df.columns:
        su_for_avg = susi_df.copy()

        # ê°€ëŠ¥í•˜ë©´ êµê³¼ ì „í˜•ë§Œ ì‚¬ìš©
        if "ì „í˜•ì„¸ë¶€ìœ í˜•" in su_for_avg.columns:
            mask = su_for_avg["ì „í˜•ì„¸ë¶€ìœ í˜•"].astype(str).str.contains("êµê³¼")
            su_for_avg = su_for_avg[mask]

        if {"ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„ëª…"}.issubset(su_for_avg.columns):
            SU_DEPT_AVG = (
                su_for_avg
                .groupby(["ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„ëª…"], as_index=False)[SUSI_GRADE_COL]
                .mean()
                .rename(columns={SUSI_GRADE_COL: "ìˆ˜ì‹œí‰ê· ë‚´ì‹ "})
            )

if jeong_df is not None:
    cand = [c for c in jeong_df.columns if "ë°˜ì˜ì˜ì—­í‰ê· ë°±ë¶„ìœ„" in c.replace(" ", "")]
    JEONG_SCORE_COL = cand[0] if cand else None


# ---------------- í•¨ì°½ê³  ìˆ˜ì‹œì§„í•™ ë°ì´í„° ê°€ê³µ ----------------
SUJI_HAS_DATA = suji_df is not None and not suji_df.empty

def decide_admit(row):
    reg = str(row.get("ë“±ë¡ì—¬ë¶€", ""))
    final = str(row.get("ìµœì¢…ë‹¨ê³„", ""))
    reason = str(row.get("ë¶ˆí•©ê²©ì‚¬ìœ ", ""))

    negative_keywords = ["ë¶ˆí•©ê²©", "ë¯¸ë“±ë¡", "íƒˆë½", "í¬ê¸°", "ìµœì €ë¯¸ì¶©ì¡±", "ìµœì €ë¯¸ë‹¬"]
    if any(neg in reason for neg in negative_keywords):
        return False

    positive_keywords_reg = ["ë“±ë¡", "í•©ê²©"]
    positive_keywords_final = ["í•©ê²©", "ìµœì¢…í•©ê²©", "ì¶”ê°€í•©ê²©", "ì¶”í•©"]

    if any(pos in reg for pos in positive_keywords_reg):
        return True
    if any(pos in final for pos in positive_keywords_final):
        return True

    return False


if SUJI_HAS_DATA:
    grade_cols = [c for c in suji_df.columns if "ë“±ê¸‰" in c and not any(
        x in c for x in ["í•œêµ­ì‚¬", "íƒêµ¬", "ì œ2ì™¸"]
    )]

    main_grade_col = None
    for key in ["ì¼ë°˜ë“±ê¸‰", "ë‚´ë“±ê¸‰(í™˜ì‚°)", "ì „êµê³¼í‰ê· ë“±ê¸‰", "ì „êµê³¼"]:
        col_norm = key.replace(" ", "")
        if col_norm in suji_df.columns:
            main_grade_col = col_norm
            break
    if main_grade_col is None and grade_cols:
        main_grade_col = grade_cols[0]

    if main_grade_col is not None:
        suji_df["ëŒ€í‘œë“±ê¸‰"] = pd.to_numeric(suji_df[main_grade_col], errors="coerce")
    else:
        suji_df["ëŒ€í‘œë“±ê¸‰"] = np.nan

    suji_df["í•©ê²©"] = suji_df.apply(decide_admit, axis=1)
# ---------------- í•™ìƒ ì…ë ¥ ìœ í‹¸ ----------------
def get_student_inputs():
    st.markdown("#### 1) ë‚´ ê¸°ë³¸ ì„±ì  ì…ë ¥")
    col1, col2 = st.columns(2)
    with col1:
        my_grade = st.number_input(
            "ë‚´ì‹  ëŒ€í‘œ ë“±ê¸‰(ì „êµê³¼ ë˜ëŠ” êµ­ìˆ˜ì˜ í‰ê· )",
            min_value=1.0, max_value=9.0, step=1.0, value=3.0,
        )
    with col2:
        mock_percent_input = st.number_input(
            "ìµœê·¼ ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ í‰ê·  (ì—†ìœ¼ë©´ 0)",
            min_value=0.0, max_value=100.0, step=1.0, value=0.0,
        )

    # â˜… ì¶”ê°€: í¬ë§ ëŒ€í•™ / í¬ë§ í•™ê³¼ ì…ë ¥
    st.markdown("#### 1-1) í¬ë§ ëŒ€í•™/í•™ê³¼ ì…ë ¥")
    col_u1, col_u2 = st.columns(2)
    with col_u1:
        target_univ = st.text_input("í¬ë§ ëŒ€í•™ (ì„ íƒ ì…ë ¥)", "")
    with col_u2:
        target_major = st.text_input("í¬ë§ í•™ê³¼ ë˜ëŠ” ëª¨ì§‘ë‹¨ìœ„ (ì„ íƒ ì…ë ¥)", "")

    st.write("ê³¼ëª©ë³„ ë“±ê¸‰(ì„ íƒ ì…ë ¥, ë°±ë¶„ìœ„ ì¶”ì •ìš©)")

    r1c1, r1c2, r2c1 = st.columns(3)
    with r1c1:
        g_kor = st.number_input("êµ­ì–´ ë“±ê¸‰", 0.0, 9.0, 0.0, 1.0)
        g_eng = st.number_input("ì˜ì–´ ë“±ê¸‰", 0.0, 9.0, 0.0, 1.0)
    with r1c2:
        g_math = st.number_input("ìˆ˜í•™ ë“±ê¸‰", 0.0, 9.0, 0.0, 1.0)
        g_t1 = st.number_input("íƒêµ¬1 ë“±ê¸‰", 0.0, 9.0, 0.0, 1.0)
    with r2c1:
        g_t2 = st.number_input("íƒêµ¬2 ë“±ê¸‰", 0.0, 9.0, 0.0, 1.0)
        g_hist = st.number_input("í•œêµ­ì‚¬ ë“±ê¸‰", 0.0, 9.0, 0.0, 1.0)

    # ë°±ë¶„ìœ„ ì¶”ì •
    grade_list = [g for g in [g_kor, g_math, g_eng, g_t1, g_t2] if g > 0]
    mock_percent_est = None
    if grade_list:
        mapping = {1: 96, 2: 89, 3: 77, 4: 62, 5: 47, 6: 32, 7: 20, 8: 11, 9: 4}
        perc = [mapping.get(int(round(g)), 50) for g in grade_list]
        mock_percent_est = float(np.mean(perc))

    mock_percentile = mock_percent_input if mock_percent_input > 0 else mock_percent_est

    region_options = ["ì„œìš¸", "ê²½ê¸°", "ì¸ì²œ", "ë¶€ì‚°", "ëŒ€êµ¬", "ê²½ë¶", "ì¶©ë¶", "ì¶©ë‚¨"]
    selected_regions = st.multiselect(
        "í¬ë§ ì§€ì—­ ì„ íƒ", options=region_options, default=region_options
    )

    # ë°˜í™˜ê°’ì— í¬ë§ ëŒ€í•™/í•™ê³¼ í¬í•¨
    return (
        my_grade,
        mock_percentile,
        selected_regions,
        target_univ,   # â˜…ì¶”ê°€
        target_major   # â˜…ì¶”ê°€
    )


# ---------------- í•™ìƒë¶€ì¢…í•© ìê°€ì§„ë‹¨ ----------------
def render_jagajin_inside_tab():
    st.markdown("### í•™ìƒë¶€ ì¢…í•© ì „í˜• ì í•©ë„ ìê°€ì§„ë‹¨")
    st.write("ê° ë¬¸í•­ì— ëŒ€í•´ 1ì (ë§¤ìš° ë¶€ì¡±) ~ 5ì (ë§¤ìš° ìš°ìˆ˜) ì‚¬ì´ì—ì„œ ì„ íƒí•´ ì£¼ì„¸ìš”.")

    questions = [
        "1) ì´ìˆ˜ ê³¼ëª© ìˆ˜ì™€ ë‚œë„ê°€ ì¶©ë¶„íˆ ë‹¤ì–‘í•œ í¸ì´ë‹¤.",
        "2) êµê³¼ ì„±ì·¨ë„ê°€ í•™ë…„ ì „ì²´ì—ì„œ ìƒìœ„ê¶Œì— ì†í•œë‹¤.",
        "3) ììœ¨/ì§„ë¡œ/ë™ì•„ë¦¬ í™œë™ì„ ì§€ì†ì Â·ì£¼ë„ì ìœ¼ë¡œ ìˆ˜í–‰í–ˆë‹¤.",
        "4) ë¦¬ë”ì‹­Â·ë°°ë ¤Â·ë´‰ì‚¬Â·ì˜ì‚¬ì†Œí†µÂ·ê³µë™ì²´ ì—­ëŸ‰ì´ ì˜ ë“œëŸ¬ë‚œë‹¤.",
        "5) í”„ë¡œì íŠ¸Â·ìº í˜ì¸Â·ë³´ê³ ì„œ í™œë™ ê²½í—˜ì´ ìˆë‹¤.",
        "6) ë…ì„œ í™œë™ì´ í’ë¶€í•˜ê³ , ì „ê³µÂ·ì§„ë¡œì™€ ì—°ê²°ë˜ì–´ ìˆë‹¤.",
        "7) ì‹¤íŒ¨ ê²½í—˜ê³¼ ê·¹ë³µ ê³¼ì •ì´ êµ¬ì²´ì ìœ¼ë¡œ ì •ë¦¬ë˜ì–´ ìˆë‹¤.",
        "8) ìƒí™œê¸°ë¡ë¶€ ê¸°ì… ë‚´ìš©ì— ëŒ€í•´ ìì‹  ìˆê²Œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.",
        "9) ë°œí‘œÂ·ë©´ì ‘Â·ìŠ¤í”¼ì¹˜ ì—­ëŸ‰ì´ ë›°ì–´ë‚œ í¸ì´ë‹¤.",
        "10) í•™êµ í™œë™ ì „ì²´ë¥¼ ê´€í†µí•˜ëŠ” í‚¤ì›Œë“œÂ·ì£¼ì œê°€ ë¶„ëª…í•˜ë‹¤.",
    ]

    scores = []
    for q in questions:
        scores.append(st.slider(q, 1, 5, 3, key=f"jaga_{q}"))

    total = sum(scores)
    max_score = 5 * len(scores)
    ratio = total / max_score * 100

    st.markdown("#### ê²°ê³¼ ìš”ì•½")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ì´ì ", f"{total} / {max_score}")
        st.metric("ì í•©ë„(%)", f"{ratio:.1f}%")
    with col2:
        if total >= 30:
            level = "ì ì •"
            msg = "í•™ìƒë¶€ ì¢…í•© ì „í˜• ì§€ì›ì— ë¹„êµì  ì˜ ì¤€ë¹„ëœ í¸ì…ë‹ˆë‹¤."
        elif total >= 25:
            level = "ë³´í†µ"
            msg = "ê¸°ë³¸ì ì¸ ì¤€ë¹„ëŠ” ë˜ì–´ ìˆìœ¼ë‚˜, ëª‡ ê°€ì§€ ë³´ì™„ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            level = "ë¯¸í¡"
            msg = "í•™ìƒë¶€ ê´€ë¦¬ì™€ ì „í˜• ì „ëµì„ ë‹¤ì‹œ ì ê²€í•˜ëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤."
        st.subheader(f"ì¢…í•© í‰ê°€: {level}")
        st.write(msg)

    st.markdown("#### ë¬¸í•­ë³„ ì ìˆ˜ ë¶„í¬")
    df = pd.DataFrame({"ë¬¸í•­": [f"Q{i+1}" for i in range(len(scores))], "ì ìˆ˜": scores})

    c1, c2 = st.columns(2)
    half = len(df) // 2
    with c1:
        st.bar_chart(df.iloc[:half].set_index("ë¬¸í•­"))
    with c2:
        st.bar_chart(df.iloc[half:].set_index("ë¬¸í•­"))
# ---------------- ë·° 1: í•¨ì°½ê³  ë“±ê¸‰ëŒ€ ë¶„ì„ ----------------
def view_grade_analysis():
    st.header("í•¨ì°½ê³  ë“±ê¸‰ëŒ€ ë¶„ì„")
    if not SUJI_HAS_DATA:
        st.error("í•¨ì°½ê³  ìˆ˜ì‹œì§„í•™ê´€ë¦¬ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = suji_df.copy()
    df = df.dropna(subset=["ëŒ€í‘œë“±ê¸‰"])

    # --- í•„í„° UI ---
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        min_g = float(np.floor(df["ëŒ€í‘œë“±ê¸‰"].min()))
        max_g = float(np.ceil(df["ëŒ€í‘œë“±ê¸‰"].max()))
        grade_min, grade_max = st.slider(
            "ëŒ€í‘œë“±ê¸‰ ë²”ìœ„ ì„ íƒ",
            min_value=min_g,
            max_value=max_g,
            value=(min_g, max_g),
            step=1.0,
        )
    with col2:
        year_options = sorted(df["ì…ì‹œì—°ë„"].dropna().unique())
        default_years = [year_options[-1]] if year_options else []
        selected_years = st.multiselect("ì…ì‹œ ì—°ë„", options=year_options, default=default_years)
    with col3:
        region = st.multiselect("ì§€ì—­ ì„ íƒ", options=sorted(df["ì§€ì—­"].dropna().unique()))
    with col4:
        univ = st.multiselect("ëŒ€í•™ ì„ íƒ", options=sorted(df["ëŒ€í•™ëª…"].dropna().unique()))

    major_keyword = st.text_input("í•™ê³¼(ëª¨ì§‘ë‹¨ìœ„) í‚¤ì›Œë“œ", "")

    # --- í•„í„° ì ìš© ---
    filtered = df[(df["ëŒ€í‘œë“±ê¸‰"] >= grade_min) & (df["ëŒ€í‘œë“±ê¸‰"] <= grade_max)]
    if selected_years:
        filtered = filtered[filtered["ì…ì‹œì—°ë„"].isin(selected_years)]
    if region:
        filtered = filtered[filtered["ì§€ì—­"].isin(region)]
    if univ:
        filtered = filtered[filtered["ëŒ€í•™ëª…"].isin(univ)]
    if major_keyword:
        filtered = filtered[filtered["ëª¨ì§‘ë‹¨ìœ„"].astype(str).str.contains(major_keyword)]

    if filtered.empty:
        st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    vt_col = "ì „í˜•ìœ í˜•" if "ì „í˜•ìœ í˜•" in filtered.columns else "ì „í˜•ëª…(ëŒ€)"
    base = filtered.assign(
        ì „í˜•ë¶„ë¥˜=lambda d: d[vt_col]
        .astype(str)
        .str.extract("(êµê³¼|ì¢…í•©|ë†ì–´ì´Œ)", expand=False)
        .fillna("ê¸°íƒ€")
    )

    admit_only = base[base["í•©ê²©"]]

    # --------- í•©ê²©ì ì§€ì—­ ë¶„í¬ ----------
    st.subheader("í•©ê²©ì ì§€ì—­ ë¶„í¬")
    if admit_only.empty:
        st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” í•©ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        region_count = (
            admit_only.groupby("ì§€ì—­")
            .size()
            .reset_index(name="í•©ê²©ììˆ˜")
            .sort_values("í•©ê²©ììˆ˜", ascending=False)
        )

        top_region = region_count.iloc[0]["ì§€ì—­"]
        top_count = int(region_count.iloc[0]["í•©ê²©ììˆ˜"])

        chart = (
            alt.Chart(region_count)
            .mark_bar()
            .encode(
                x=alt.X("ì§€ì—­:O", sort="-y", axis=alt.Axis(labelAngle=0)),
                y=alt.Y("í•©ê²©ììˆ˜:Q"),
                color=alt.condition(
                    alt.datum.ì§€ì—­ == top_region,
                    alt.value("#ff7f0e"),
                    alt.value("#1f77b4"),
                ),
            )
            .properties(height=300)
        )

        st.altair_chart(chart, use_container_width=True)
        st.markdown(f"**ê°€ì¥ ë§ì€ ì§€ì—­: {top_region} (í•©ê²© {top_count}ëª…)**")

    # --------- í•©ê²© ì „í˜• ë¶„í¬ & ìµœì € ì¶©ì¡±ë¥  ----------
    st.subheader("í•©ê²© ì „í˜• ë° ìµœì € ì¶©ì¡±ë¥ ")

    col_left, col_right = st.columns(2)

    with col_left:
        st.markdown("##### í•©ê²© ì „í˜• ë¶„í¬")
        if admit_only.empty:
            st.info("í•©ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            vt_count = (
                admit_only.groupby("ì „í˜•ë¶„ë¥˜")
                .size()
                .reset_index(name="í•©ê²©ììˆ˜")
            )
            pie = (
                alt.Chart(vt_count)
                .mark_arc()
                .encode(
                    theta="í•©ê²©ììˆ˜:Q",
                    color="ì „í˜•ë¶„ë¥˜:N",
                    tooltip=["ì „í˜•ë¶„ë¥˜", "í•©ê²©ììˆ˜"],
                )
            )
            st.altair_chart(pie, use_container_width=True)

    with col_right:
        st.markdown("##### ìµœì € ì¶©ì¡±ë¥  (ìµœì €ê°€ ìˆëŠ” ì „í˜• ê¸°ì¤€)")
        min_cols = [c for c in base.columns if "ìµœì €" in c]
        min_col = min_cols[0] if min_cols else None

        if min_col is None:
            st.info("ìµœì €í•™ë ¥ ê¸°ì¤€ ì •ë³´ê°€ ì—†ì–´ ì¶©ì¡±ë¥ ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            cond_has_min = (
                base[min_col].notna()
                & (base[min_col].astype(str).str.strip() != "")
                & (~base[min_col].astype(str).str.contains("ì—†ìŒ"))
            )
            base_min = base[cond_has_min].copy()

            if base_min.empty:
                st.info("ìµœì €í•™ë ¥ ê¸°ì¤€ì´ ì„¤ì •ëœ ì „í˜•ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                min_stats = (
                    base_min.groupby("ì „í˜•ë¶„ë¥˜")["í•©ê²©"]
                    .mean()
                    .reset_index(name="ìµœì €ì¶©ì¡±ë¥ ")
                )
                min_stats["ìµœì €ì¶©ì¡±ë¥ (%)"] = (min_stats["ìµœì €ì¶©ì¡±ë¥ "] * 100).round(1)

                bar = (
                    alt.Chart(min_stats)
                    .mark_bar()
                    .encode(
                        x=alt.X("ì „í˜•ë¶„ë¥˜:O", axis=alt.Axis(labelAngle=0)),
                        y=alt.Y("ìµœì €ì¶©ì¡±ë¥ (%):Q"),
                        tooltip=["ì „í˜•ë¶„ë¥˜", "ìµœì €ì¶©ì¡±ë¥ (%)"],
                    )
                    .properties(height=300)
                )
                st.altair_chart(bar, use_container_width=True)
                
    # --------- ìƒì„¸ í‘œ ----------
    st.markdown("---")
    st.markdown("#### í•„í„° ì¡°ê±´ì— ë”°ë¥¸ ìƒì„¸ í•©ê²© í•™ê³¼ ëª©ë¡ (í•¨ì°½ê³  ì…ê²°)")

    detail = base[base["í•©ê²©"]].copy()
    if detail.empty:
        st.info("ì¡°ê±´ì— ë§ëŠ” í•©ê²© í•™ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì´ë¦„ ë§ˆìŠ¤í‚¹
    if "ì´ë¦„" in detail.columns:
        detail["ì´ë¦„ë§ˆìŠ¤í‚¹"] = detail["ì´ë¦„"].astype(str).str[0] + "OO"
    else:
        detail["ì´ë¦„ë§ˆìŠ¤í‚¹"] = ""

    # ì§€ì›ì „í˜•
    if "ì „í˜•ìœ í˜•" in detail.columns:
        detail["ì§€ì›ì „í˜•"] = detail["ì „í˜•ìœ í˜•"]
    else:
        detail["ì§€ì›ì „í˜•"] = detail.get("ì „í˜•ëª…(ëŒ€)", "")

    # ì„¸ë¶€ìœ í˜• (CSV ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    detail["ì„¸ë¶€ìœ í˜•"] = detail.get("ì„¸ë¶€ìœ í˜•", "")

    # --- ì„¸ë¶€ìœ í˜• í•„í„° ì¶”ê°€ ---
    if "ì„¸ë¶€ìœ í˜•" in detail.columns:
        type_options = sorted(detail["ì„¸ë¶€ìœ í˜•"].dropna().unique())
        selected_types = st.multiselect(
            "ì„¸ë¶€ìœ í˜• í•„í„°",
            options=type_options,
            default=type_options
        )
        detail = detail[detail["ì„¸ë¶€ìœ í˜•"].isin(selected_types)]

    # ìµœì € ì •ë³´
    min_cols = [c for c in detail.columns if "ìµœì €" in c]
    if min_cols:
        mc = min_cols[0]
        detail["ìµœì €"] = detail[mc].fillna("ì—†ìŒ").replace("", "ì—†ìŒ")
    else:
        detail["ìµœì €"] = "ì—†ìŒ"

    # í‘œ ì»¬ëŸ¼
    cols_for_table = [
        "ì…ì‹œì—°ë„",
        "ì´ë¦„ë§ˆìŠ¤í‚¹",
        "ëŒ€í‘œë“±ê¸‰",
        "ì§€ì—­",
        "ëŒ€í•™ëª…",
        "ëª¨ì§‘ë‹¨ìœ„",
        "ì§€ì›ì „í˜•",
        "ì„¸ë¶€ìœ í˜•",
        "ìµœì €",
    ]
    cols_for_table = [c for c in cols_for_table if c in detail.columns]

    table_df = detail[cols_for_table].sort_values(
        ["ì…ì‹œì—°ë„", "ëŒ€í‘œë“±ê¸‰", "ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„"]
    )
    st.dataframe(table_df, use_container_width=True, hide_index=True)

    
# ---------------- ì¶”ì²œ ê³µí†µ ìœ í‹¸ ----------------
def pick_recommendations(df, label_col, diff_col, top_n=3):
    results = []

    safe = df[df[label_col] == "ìƒí–¥(ë„ì „)"]
    if not safe.empty:
        results.append(safe.nsmallest(top_n, diff_col))

    mid = df[df[label_col] == "ì ì •"].copy()
    if not mid.empty:
        mid = mid.loc[mid[diff_col].abs().sort_values().index].head(top_n)
        results.append(mid)

    risk = df[df[label_col] == "ì•ˆì „"]
    if not risk.empty:
        results.append(risk.nlargest(top_n, diff_col))

    if not results:
        return pd.DataFrame(columns=df.columns)

    rec = pd.concat(results, ignore_index=True)

    dedup_keys = [c for c in ["ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„"] if c in rec.columns]
    if dedup_keys:
        rec = rec.drop_duplicates(subset=dedup_keys, keep="first")

    return rec


# ---------------- ë·° 2: ìˆ˜ì‹œÂ·ì •ì‹œ ì¶”ì²œ íƒìƒ‰ê¸° ----------------
def view_recommend():
    st.header("ìˆ˜ì‹œÂ·ì •ì‹œ ì¶”ì²œ íƒìƒ‰ê¸°")

    # â˜… ìˆ˜ì •: í¬ë§ëŒ€í•™/í•™ê³¼ê¹Œì§€ ì…ë ¥ë°›ìŒ
    my_grade, mock_percentile, regions, target_univ, target_major = get_student_inputs()

    tab_su, tab_je, tab_jg = st.tabs(["ìˆ˜ì‹œ ì¶”ì²œ", "ì •ì‹œ ì¶”ì²œ", "í•™ìƒë¶€ì¢…í•© ìê°€ì§„ë‹¨"])

    # ---- ìˆ˜ì‹œ ì¶”ì²œ ----
    with tab_su:
        st.subheader("ìˆ˜ì‹œ ì¶”ì²œ ëŒ€í•™ (ì–´ë””ê°€ ì‚¬ì´íŠ¸ ì…ê²° ê¸°ì¤€)")

        if not SUJI_HAS_DATA:
            st.warning(
                "ìš°ë¦¬ í•™êµ ìˆ˜ì‹œ í•©ê²© ë‚´ì—­ì´ ë¶€ì¡±í•˜ì—¬ ì¶”ì²œ ê³„ì‚°ì´ ì–´ë µìŠµë‹ˆë‹¤.\n\n"
                "ìƒë‹¨ 'í•¨ì°½ê³  ë“±ê¸‰ëŒ€ ë¶„ì„' ë©”ë‰´ì—ì„œ ì „ì²´ í•©ê²© ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        else:
            df = suji_df.copy()
            df = df[df["í•©ê²©"]]
            df = df.dropna(subset=["ëŒ€í‘œë“±ê¸‰"])

            if "ì§€ì—­" in df.columns and regions:
                df = df[df["ì§€ì—­"].isin(regions)]

            if df.empty:
                st.info("ì„ íƒí•œ ì§€ì—­ì—ì„œ í•©ê²© ë‚´ì‹  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            else:
                group_cols = [c for c in ["ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„", "ì „í˜•ìœ í˜•"] if c in df.columns]
                agg = (
                    df.groupby(group_cols, as_index=False)["ëŒ€í‘œë“±ê¸‰"]
                    .mean()
                    .rename(columns={"ëŒ€í‘œë“±ê¸‰": "í•©ê²©í‰ê· ë‚´ì‹ "})
                )

                agg["ë‚´ì‹ ì°¨ì´(í•©-ì…)"] = agg["í•©ê²©í‰ê· ë‚´ì‹ "] - my_grade

                def label_row(d):
                    diff = d["ë‚´ì‹ ì°¨ì´(í•©-ì…)"]
                    if diff > 0.3:
                        return "ì•ˆì „"
                    if diff < -0.3:
                        return "ìƒí–¥(ë„ì „)"
                    return "ì ì •"

                agg["ì¶”ì²œêµ¬ë¶„"] = agg.apply(label_row, axis=1)

                # â˜… ì¶”ê°€: í¬ë§ ëŒ€í•™ / í•™ê³¼ í•„í„°
                if target_univ:
                    agg = agg[agg["ëŒ€í•™ëª…"].astype(str).str.contains(target_univ)]
                if target_major:
                    agg = agg[agg["ëª¨ì§‘ë‹¨ìœ„"].astype(str).str.contains(target_major)]

                rec = pick_recommendations(agg, "ì¶”ì²œêµ¬ë¶„", "ë‚´ì‹ ì°¨ì´(í•©-ì…)", top_n=3)

                cols = ["ì¶”ì²œêµ¬ë¶„"] + [c for c in ["ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„", "ì „í˜•ìœ í˜•"] if c in rec.columns] + [
                    "í•©ê²©í‰ê· ë‚´ì‹ ",
                    "ë‚´ì‹ ì°¨ì´(í•©-ì…)",
                ]
                if not rec.empty:
                    st.dataframe(rec[cols], use_container_width=True, hide_index=True)
                else:
                    st.info("ì¶”ì²œí•  ë§Œí•œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # ---- ì •ì‹œ ì¶”ì²œ ----
    with tab_je:
        st.subheader("ì •ì‹œ ì¶”ì²œ ëŒ€í•™ (ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ ê¸°ì¤€)")

        if jeong_df is None or JEONG_SCORE_COL is None:
            st.warning("ì •ì‹œ ì…ê²° ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì •ì‹œ ì¶”ì²œ ê³„ì‚°ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if mock_percentile is None:
                st.info("ì •ì‹œ ì¶”ì²œì„ ìœ„í•´ ëª¨ì˜ê³ ì‚¬ ë°±ë¶„ìœ„ ì…ë ¥ ë˜ëŠ” ê³¼ëª© ë“±ê¸‰ ì…ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                dfj = jeong_df.copy()
                if "ì§€ì—­êµ¬ë¶„" in dfj.columns and regions:
                    dfj = dfj[dfj["ì§€ì—­êµ¬ë¶„"].isin(regions)]

                dfj[JEONG_SCORE_COL] = pd.to_numeric(dfj[JEONG_SCORE_COL], errors="coerce")
                dfj = dfj.dropna(subset=[JEONG_SCORE_COL])

                if dfj.empty:
                    st.warning("í•´ë‹¹ ì§€ì—­ì—ì„œ ì •ì‹œ ì…ê²° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    dfj["ì •ì‹œí‰ê· ë°±ë¶„ìœ„"] = dfj[JEONG_SCORE_COL]
                    dfj["ë°±ë¶„ìœ„ì°¨ì´(í•©-ì…)"] = dfj["ì •ì‹œí‰ê· ë°±ë¶„ìœ„"] - mock_percentile

                    def label_j(row):
                        d = row["ë°±ë¶„ìœ„ì°¨ì´(í•©-ì…)"]
                        if d > 3:
                            return "ìƒí–¥(ë„ì „)"
                        if d < -3:
                            return "ì•ˆì „"
                        return "ì ì •"

                    dfj["ì¶”ì²œêµ¬ë¶„"] = dfj.apply(label_j, axis=1)

                    # â˜… ì¶”ê°€: í¬ë§ ëŒ€í•™/í•™ê³¼ í•„í„°
                    if target_univ:
                        dfj = dfj[dfj["ëŒ€í•™ëª…"].astype(str).str.contains(target_univ)]
                    if target_major:
                        dfj = dfj[dfj["ëª¨ì§‘ë‹¨ìœ„"].astype(str).str.contains(target_major)]

                    recj = pick_recommendations(dfj, "ì¶”ì²œêµ¬ë¶„", "ë°±ë¶„ìœ„ì°¨ì´(í•©-ì…)", top_n=3)

                    if SU_DEPT_AVG is not None and {"ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„"}.issubset(recj.columns):
                        recj = recj.merge(
                            SU_DEPT_AVG,
                            how="left",
                            left_on=["ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„"],
                            right_on=["ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„ëª…"],
                        )

                    colsj = ["ì¶”ì²œêµ¬ë¶„", "ëŒ€í•™ëª…", "ì „í˜•ëª…", "ëª¨ì§‘êµ°", "ëª¨ì§‘ë‹¨ìœ„", "ì •ì‹œí‰ê· ë°±ë¶„ìœ„", "ë°±ë¶„ìœ„ì°¨ì´(í•©-ì…)"]
                    if "ìˆ˜ì‹œí‰ê· ë‚´ì‹ " in recj.columns:
                        colsj.append("ìˆ˜ì‹œí‰ê· ë‚´ì‹ ")

                    st.dataframe(recj[colsj], use_container_width=True, hide_index=True)

    # ---- í•™ìƒë¶€ì¢…í•© ìê°€ì§„ë‹¨ ----
    with tab_jg:
        render_jagajin_inside_tab()


# ---------------- ìµœì € ê¸°ì¤€ ëŒ€í•™ ì°¾ê¸° ----------------
def parse_minimum_rule(rule_text, grades):
    if not rule_text or not isinstance(rule_text, str):
        return False

    text = rule_text.replace(" ", "")
    nums = [g for g in [grades["êµ­ì–´"], grades["ìˆ˜í•™"], grades["ì˜ì–´"], grades["íƒ1"], grades["íƒ2"], grades["í•œêµ­ì‚¬"]] if g > 0]
    if not nums:
        return False

    m_each = re.search(r"(\d)ë“±ê¸‰ì´ë‚´", text)
    if m_each:
        limit = int(m_each.group(1))
        return all(g <= limit for g in nums)

    m_sum = re.search(r"(?:ì¤‘)?(\d)ê°œì˜ì—­?í•©(\d+)ì´ë‚´", text)
    if m_sum:
        n = int(m_sum.group(1))
        s_limit = int(m_sum.group(2))
        nums_sorted = sorted(nums)
        if len(nums_sorted) < n:
            return False
        return sum(nums_sorted[:n]) <= s_limit

    m_each2 = re.search(r"ê°(\d)ë“±ê¸‰", text)
    if m_each2:
        limit = int(m_each2.group(1))
        return all(g <= limit for g in nums)

    return False


def view_choejeo():
    st.header("ìµœì € ê¸°ì¤€ìœ¼ë¡œ ëŒ€í•™ ì°¾ê¸°")

    if choe_df is None:
        st.error("2025 ìµœì € ê¸°ì¤€ ë°ì´í„°(2025ìµœì €ëª¨ìŒ.csv)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.markdown("### 1) ë‚´ í¬ë§ ìµœì € ê¸°ì¤€ ì…ë ¥")

    row1 = st.columns(3)
    with row1[0]:
        g_k = st.number_input("êµ­ì–´ ìµœëŒ€ ë“±ê¸‰(0=ë¯¸ì‚¬ìš©)", 0.0, 9.0, 0.0, 1.0, key="min_k")
    with row1[1]:
        g_e = st.number_input("ì˜ì–´ ìµœëŒ€ ë“±ê¸‰(0=ë¯¸ì‚¬ìš©)", 0.0, 9.0, 0.0, 1.0, key="min_e")
    with row1[2]:
        g_m = st.number_input("ìˆ˜í•™ ìµœëŒ€ ë“±ê¸‰(0=ë¯¸ì‚¬ìš©)", 0.0, 9.0, 0.0, 1.0, key="min_m")

    row2 = st.columns(3)
    with row2[0]:
        g_t1 = st.number_input("íƒêµ¬1 ìµœëŒ€ ë“±ê¸‰(0=ë¯¸ì‚¬ìš©)", 0.0, 9.0, 0.0, 1.0, key="min_t1")
    with row2[1]:
        g_t2 = st.number_input("íƒêµ¬2 ìµœëŒ€ ë“±ê¸‰(0=ë¯¸ì‚¬ìš©)", 0.0, 9.0, 0.0, 1.0, key="min_t2")
    with row2[2]:
        g_h = st.number_input("í•œêµ­ì‚¬ ìµœëŒ€ ë“±ê¸‰(0=ë¯¸ì‚¬ìš©)", 0.0, 9.0, 0.0, 1.0, key="min_h")

    st.caption("â€» 0ìœ¼ë¡œ ë‘ë©´ í•´ë‹¹ ê³¼ëª©ì€ ìµœì € ê¸°ì¤€ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.")

    colr1, colr2 = st.columns([2, 1])
    with colr1:
        regions = st.multiselect(
            "ì§€ì—­ ì„ íƒ",
            options=sorted(choe_df["ì§€ì—­êµ¬ë¶„"].dropna().unique()),
            default=None,
        )
    with colr2:
        keyword = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ (ëŒ€í•™ëª…/ëª¨ì§‘ë‹¨ìœ„/ë‚´ìš© ì¼ë¶€)", "")

    my_grades = {"êµ­ì–´": g_k, "ìˆ˜í•™": g_m, "ì˜ì–´": g_e, "íƒ1": g_t1, "íƒ2": g_t2, "í•œêµ­ì‚¬": g_h}

    st.markdown("### 2) ìµœì € ê¸°ì¤€ì— ë§ëŠ” ëŒ€í•™ ê²€ìƒ‰")

    if st.button("ìµœì € ê¸°ì¤€ì— ë§ëŠ” ëŒ€í•™ ê²€ìƒ‰", type="primary"):
        df = choe_df.copy()
        if regions:
            df = df[df["ì§€ì—­êµ¬ë¶„"].isin(regions)]
        if keyword:
            pattern = keyword.replace(" ", "")
            df = df[
                df["ëŒ€í•™ëª…"].astype(str).str.contains(pattern)
                | df["ëª¨ì§‘ë‹¨ìœ„ëª…"].astype(str).str.contains(pattern)
                | df["ìµœì €í•™ë ¥ê¸°ì¤€ë‚´ìš©"].astype(str).str.contains(pattern)
            ]

        if df.empty:
            st.warning("ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        df["ìµœì €ì¶©ì¡±ê°€ëŠ¥"] = df["ìµœì €í•™ë ¥ê¸°ì¤€ë‚´ìš©"].apply(
            lambda x: parse_minimum_rule(x, my_grades)
        )
        df_ok = df[df["ìµœì €ì¶©ì¡±ê°€ëŠ¥"]]

        if df_ok.empty:
            st.info("ì…ë ¥ ì¡°ê±´ì— ë§ëŠ” ëŒ€í•™ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        if SU_DEPT_AVG is not None and {"ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„ëª…"}.issubset(df_ok.columns):
            df_ok = df_ok.merge(SU_DEPT_AVG, how="left", on=["ëŒ€í•™ëª…", "ëª¨ì§‘ë‹¨ìœ„ëª…"])

        cols = ["ì§€ì—­êµ¬ë¶„", "ëŒ€í•™ëª…", "ì „í˜•ì„¸ë¶€ìœ í˜•", "ëª¨ì§‘ë‹¨ìœ„ëª…", "ìµœì €í•™ë ¥ê¸°ì¤€ë‚´ìš©"]
        if "ìˆ˜ì‹œí‰ê· ë‚´ì‹ " in df_ok.columns:
            cols.append("ìˆ˜ì‹œí‰ê· ë‚´ì‹ ")

        st.dataframe(df_ok[cols], use_container_width=True, hide_index=True)


# ---------------- ì‚¬ì´ë“œë°” ë©”ë‰´ ----------------
with st.sidebar:
    st.markdown("### ë©”ë‰´ ì„ íƒ")
    menu = st.radio(
        "",
        ["í•¨ì°½ê³  ë“±ê¸‰ëŒ€ ë¶„ì„", "ìˆ˜ì‹œÂ·ì •ì‹œ ì¶”ì²œ íƒìƒ‰ê¸°", "ìµœì € ê¸°ì¤€ìœ¼ë¡œ ëŒ€í•™ ì°¾ê¸°"],
    )
    st.markdown("---")
    st.markdown(
        "<div style='font-size:0.85rem; color:gray;'>ì œì‘ì í•¨ì°½ê³  êµì‚¬ ë°•í˜¸ì¢…</div>",
        unsafe_allow_html=True,
    )


# ---------------- ë¼ìš°íŒ… ----------------
if menu == "í•¨ì°½ê³  ë“±ê¸‰ëŒ€ ë¶„ì„":
    view_grade_analysis()
elif menu == "ìˆ˜ì‹œÂ·ì •ì‹œ ì¶”ì²œ íƒìƒ‰ê¸°":
    view_recommend()
elif menu == "ìµœì € ê¸°ì¤€ìœ¼ë¡œ ëŒ€í•™ ì°¾ê¸°":
    view_choejeo()

st.markdown("---")
st.markdown(
    "<div style='text-align:center; font-size:0.85rem; color:gray;'>ì œì‘ì í•¨ì°½ê³  êµì‚¬ ë°•í˜¸ì¢…</div>",
    unsafe_allow_html=True,
)













